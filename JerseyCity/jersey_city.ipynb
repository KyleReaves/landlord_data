{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jersey City Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### These notebooks are my attempt to clean and geocode property tax records\n",
    "### This data will be used by MapBoxGL \n",
    "### This is not a robust or data-scientific approach; I was shooting in the dark, \n",
    "### cleaning strings individually until I returned fewer and fewer errors.\n",
    "### Not all errors have been corrected. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "geolocator = Nominatim(user_agent=\"myGeolocator\", timeout=2)\n",
    "\n",
    "\n",
    "# loading saved objects into dataframe\n",
    "errors_df = pd.read_pickle('errors_df.pkl')\n",
    "df = pd.read_pickle('jersey_city.pkl')\n",
    "\n",
    "# dataframe for public housing:\n",
    "# eventually, these dataframes will be joined in someway which preserves both property types\n",
    "# until then I will be dealing with them separately\n",
    "# public_housing_df = pd.read_csv('JerseyCity_PublicHousing.csv')\n",
    "public_housing_df = pd.read_pickle('public_housing_df.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending the path to access my helper functions\n",
    "sys.path.append('/Users/kylereaves/src/landlord_data/')\n",
    "\n",
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_properties(owner):\n",
    "    return df[df.owner_name == owner]['street_address'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['list_properties_owned'] = [get_properties(owner) for owner in df.owner_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using convert_dtypes() to infer types from columns\n",
    "df = df.convert_dtypes(infer_objects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42030 entries, 0 to 42029\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   street_address              42030 non-null  string \n",
      " 1   owner_name                  42030 non-null  string \n",
      " 2   owner_mailing_address       42030 non-null  string \n",
      " 3   city_state_zip              42030 non-null  string \n",
      " 4   owner_full_mailing_address  42030 non-null  string \n",
      " 5   property_full_address       42030 non-null  string \n",
      " 6   number_properties_owned     42030 non-null  Int64  \n",
      " 7   units                       42030 non-null  Int64  \n",
      " 8   g_code                      42030 non-null  object \n",
      " 9   latitude                    42030 non-null  Float64\n",
      " 10  longitude                   42030 non-null  Float64\n",
      " 11  list_properties_owned       42030 non-null  object \n",
      "dtypes: Float64(2), Int64(2), object(2), string(6)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'propertyLocation': 'street_address',\n",
    "                   'ownersName': 'owner_name',\n",
    "                   'ownersMailingAddress': 'owner_mailing_address',\n",
    "                   'cityStateZip': 'city_state_zip',\n",
    "                   'ownersFullMailingAddress': 'owner_full_mailing_address',\n",
    "                   'propertyFullAddress': 'property_full_address',\n",
    "                   'propertiesOwned': 'number_properties_owned',\n",
    "                   'gCode': 'g_code'\n",
    "                   }, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number_properties_owned'] = [len(df.list_properties_owned.iloc[i]) for i in range(0, df.index[-1]+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df.list_properties_owned.iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_housing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# public_housing_df['gCode'] = public_housing_df.propertyLocation.apply(geolocator.geocode)\n",
    "\n",
    "# def getAssociatedProperties(manager_name=str):\n",
    "#    return public_housing_df[public_housing_df.managerName == manager_name]['propertyLocation'].tolist()\n",
    "\n",
    "# public_housing_df['associatedProperties'] = [getAssociatedProperties(manager) for manager in public_housing_df.managerName]\n",
    "# public_housing_df['lat'] = [g.latitude for g in public_housing_df.gCode]\n",
    "# public_housing_df['long'] = [g.longitude for g in public_housing_df.gCode]\n",
    "# public_housing_df.to_pickle('public_housing_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check to see if there are any addresses beyond 'Jersey City'\n",
    "### if so, append them to errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.g_code.str.contains('Jersey City') == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # number of times property appears in first column\n",
    "# def propertyAppearances(address=str): \n",
    "#     return len(df[df.propertyLocation == address])\n",
    "# #\n",
    "# def getPropertiesOwned(owner=str):\n",
    "#     return df[df.ownersName == owner]['propertyLocation'].unique().tolist()\n",
    "# df['ownersFullMailingAddress'] = df['ownersMailingAddress'] + ', ' + df.cityStateZip\n",
    "# df['propertyFullAddress'] = df.propertyLocation + ', ' + 'Jersey City, NJ'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocode_errors = [i for i,e in enumerate(errors_df.gCode) if e == None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df.iloc[geocode_errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jersey_city_replacement = {\n",
    "    'TONNELE': 'TONNELLE',\n",
    "    'MC ADOO': 'MCADOO',\n",
    "    'M.L. KING DRIVE': 'MARTIN LUTHER KING DRIVE',\n",
    "    'COLUMBUS': 'CHRISTOPHER COLUMBUS',\n",
    "    'FIRST': '1st',\n",
    "    'SECOND': '2nd',\n",
    "    'THIRD': '3rd',\n",
    "    'FOURTH': '4th',\n",
    "    'FIFTH': '5th',\n",
    "    'SIXTH': '6th',\n",
    "    'SEVENTH': '7th',\n",
    "    'EIGHTH': '8th',\n",
    "    'NINETH': '9th',\n",
    "    'TENTH': '10th',\n",
    "    'NINTH': '9th',\n",
    "    'FIFTEENTH': '15th',\n",
    "    'SIXTEENTH': '16th',\n",
    "    'MC DOUGALL': 'MCDOUGALL',\n",
    "    'CARPENTIER': 'CARPENTER',\n",
    "    'FOX HOUND': 'FOXHOUND',\n",
    "    'SIEDLER': 'SEIDLER',\n",
    "    'LIENAU': 'LINEAU',\n",
    "    'KENNEDY': 'JOHN F KENNEDY',\n",
    "    'LIBERTY ST.': 'LIBERTY AVE.',\n",
    "    '-REAR': '',\n",
    "    '(REAR,': '',\n",
    "    '-FRONT': '',\n",
    "    'HAMPTON CT.': 'HAMPTON COURT',\n",
    "    'VARCK': 'VARICK',\n",
    "    'THO': '',\n",
    "    'AVE AVE': 'AVE',\n",
    "    'TER': 'TR',\n",
    "    '3633A': '3633',\n",
    "    '3144A': '3144',\n",
    "    'SHEARWATR': 'SHEARWATER',\n",
    "    'PALUSL': \"PAUL'S\",\n",
    "    'COURT TR': \"CT\",\n",
    "    'EASTVIEW': \"E VIEW\",\n",
    "    'M.L. KING DR.': 'MARTIN LUTHER KING DR.',\n",
    "    ' 1ST FL.': '',\n",
    "    ' SO.': '',\n",
    "    ' N.': '',\n",
    "    'ODGEN': 'OGDEN',\n",
    "    'PATRSON': 'PATERSON',\n",
    "    ' 61 COLES': '',\n",
    "    'VAN HOUTEN ST.': 'VAN HOUTEN AVE.',\n",
    "    'MC PHERSON ST.': 'MCPHERSON PL.',\n",
    "    'MC PHERSON': 'MCPHERSON',\n",
    "    'FIR ROAD': 'FIR ST.',\n",
    "    'UNION AVE.': 'UNION ST.',\n",
    "    'OLD BERGEN': 'OLD BERGEN AVE.',\n",
    "    'AVE. AVE.': 'AVE.',\n",
    "    'JACKSON AVE.': 'JACKSON ST.',\n",
    "    '162 OLD BERGEN AVE. AVE.': '162 OLD BERGEN AVE.',\n",
    "    'GLEN': 'GLENN',\n",
    "    'GLENNN': 'GLENN',\n",
    "    'DR.VE': 'DRIVE',\n",
    "    '1 GLENNN LANE': '1 GLENN LANE',\n",
    "    r'\\(\\,': '',\n",
    "    r'-\\d{2:}(.?\\d{1}(A,?,?A?\\b': '',\n",
    "    r'-\\d{2:}': '',\n",
    "    r'\\s#\\d': '',\n",
    "    'BUTTRNUT': 'BUTTERNUT',\n",
    "    'CARPENTR': 'CARPENTER',\n",
    "    '100 SHEARWATER CT.': '100 EAST SHEARWATER CT.',\n",
    "    '78A RNE ST.': '78 THORNE ST.',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('TONNELE', 'TONNELLE')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('MC ADOO', 'MCADOO')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('M.L. KING DRIVE', 'MARTIN LUTHER KING DRIVE')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('COLUMBUS', 'CHRISTOPHER COLUMBUS')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('FIRST', '1st')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('SECOND', '2nd')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('THIRD', '3rd')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('FOURTH', '4th')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('FIFTH', '5th')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('SIXTH', '6th')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('SEVENTH', '7th')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('EIGHTH', '8th')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('NINETH', '9th')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('TENTH', '10th')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('NINTH', '9th')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('FIFTEENTH', '15th')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('SIXTEENTH', '16th')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('MC DOUGALL', 'MCDOUGALL')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('CARPENTIER', 'CARPENTER')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('FOX HOUND', 'FOXHOUND')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('SIEDLER', 'SEIDLER')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('LIENAU', 'LINEAU')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('KENNEDY', 'JOHN F KENNEDY')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('LIBERTY ST.', 'LIBERTY AVE.')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('-REAR', '')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('(REAR)', '')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('-FRONT', '')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('HAMPTON CT.', 'HAMPTON COURT')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('VARCK', 'VARICK')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('THO', '')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('AVE AVE', 'AVE')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('TER', 'TR')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('3633A', '3633')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('3144A', '3144')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('SHEARWATR', 'SHEARWATER')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('PALUSL', \"PAUL'S\")\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('COURT TR', \"CT\")\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('EASTVIEW', \"E VIEW\")\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('M.L. KING DR.', 'MARTIN LUTHER KING DR.')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace(' 1ST FL.', '')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace(' SO.', '')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace(' N.', '')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('ODGEN', 'OGDEN')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('PATRSON', 'PATERSON')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace(' 61 COLES', '')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('VAN HOUTEN ST.', 'VAN HOUTEN AVE.')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('MC PHERSON ST.', 'MCPHERSON PL.')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('MC PHERSON', 'MCPHERSON')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('FIR ROAD', 'FIR ST.')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('UNION AVE.', 'UNION ST.')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('OLD BERGEN', 'OLD BERGEN AVE.')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('AVE. AVE.', 'AVE.')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('JACKSON AVE.', 'JACKSON ST.')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('162 OLD BERGEN AVE. AVE.', '162 OLD BERGEN AVE.')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('GLEN', 'GLENN')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('GLENNN', 'GLENN')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('DR.VE', 'DRIVE')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('1 GLENNN LANE', '1 GLENN LANE')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace(r'\\(\\)', '')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace(r'-\\d{2,}(.?\\d{1}(A)?)?A?\\b', '')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace(r'-\\d{2,}', '')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace(r'\\s#\\d', '')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('BUTTRNUT', 'BUTTERNUT')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('CARPENTR', 'CARPENTER')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('100 SHEARWATER CT.', '100 EAST SHEARWATER CT.')\n",
    "# errors_df.propertyLocation = errors_df.propertyLocation.str.replace('78A RNE ST.', '78 THORNE ST.')\n",
    "\n",
    "# overwriting past mistakes\n",
    "errors_df.propertyFullAddress = errors_df.propertyLocation + ' Jersey City, NJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "errors_df['gCode'] = errors_df.propertyFullAddress.apply(geolocator.geocode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocode_errors = [i for i,e in enumerate(errors_df.gCode) if e == None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df.iloc[geocode_errors].propertyLocation.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking to see how many unique properties remain in the errors dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors_df.iloc[geocode_errors].propertyLocation.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocode_errors = [i for i,e in enumerate(errors_df.gCode) if e == None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df.iloc[geocode_errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reassigning the errors_df to the remaining errors\n",
    "errors_df = errors_df.iloc[geocode_errors].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df.to_pickle('errors_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['latitude'] = [g.latitude for g in df.gCode]\n",
    "df['longitude'] = [g.longitude for g in df.gCode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df.propertyLocation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df['propertyFullAddress'] = errors_df.propertyLocation + ', Jersey City, NJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "errors_df['gCode'] = errors_df.propertyFullAddress.apply(geolocator.geocode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling the dataframe\n",
    "df.to_pickle('jersey_city.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exporting dataframe to csv, but indicating that i'm only exporting private property\n",
    "df.to_csv('jersey_city_private_property.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 42030 entries, 0 to 42029\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   street_address              42030 non-null  string \n",
      " 1   owner_name                  42030 non-null  string \n",
      " 2   owner_mailing_address       42030 non-null  string \n",
      " 3   city_state_zip              42030 non-null  string \n",
      " 4   owner_full_mailing_address  42030 non-null  string \n",
      " 5   property_full_address       42030 non-null  string \n",
      " 6   number_properties_owned     42030 non-null  Int64  \n",
      " 7   units                       42030 non-null  Int64  \n",
      " 8   g_code                      42030 non-null  object \n",
      " 9   latitude                    42030 non-null  Float64\n",
      " 10  longitude                   42030 non-null  Float64\n",
      " 11  list_properties_owned       42030 non-null  object \n",
      "dtypes: Float64(2), Int64(2), object(2), string(6)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
